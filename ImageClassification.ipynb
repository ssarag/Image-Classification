{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "6BHNeXYOQ0qH"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.keras.layers import Dense, Flatten, Dropout, Activation\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "dNFDpobFKrhL"
   },
   "outputs": [],
   "source": [
    "# these are labels and also the exact folder names in which each kind of images are\n",
    "\n",
    "view_map = {\n",
    "    'buildings': 0,\n",
    "    'forest': 1,\n",
    "    'glacier': 2,\n",
    "    'mountain': 3,\n",
    "    'sea': 4,\n",
    "    'street': 5,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TKA3zYoOK0iT",
    "outputId": "92182578-0a9e-46a0-eb9c-170059625e97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "fpath=r\"/content/drive/MyDrive/Image Classification/Image Classification\"          # main parent folder containing train and test\n",
    "\n",
    "frames = []\n",
    "\n",
    "for p in ['seg_train', 'seg_test']:  # train and test folder names\n",
    "    for k in view_map.keys():  # use your own label map\n",
    "        fdf = pd.DataFrame(columns=['view', 'pixels', 'height', 'width', 'usage'])  # DataFrame for image data\n",
    "        folder_path = os.path.join(fpath, p, p, k)  # Update the path\n",
    "        all_files = os.listdir(folder_path)  # List all files in the directory\n",
    "\n",
    "        for i, file in enumerate(all_files):\n",
    "            pic_path = os.path.join(folder_path, file)\n",
    "            try:\n",
    "                img = cv2.imread(pic_path)\n",
    "                if img is None:\n",
    "                    print(f\"Error: Unable to read image '{pic_path}'\")\n",
    "                    continue\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                height, width = img.shape\n",
    "                img = list(img.flatten())\n",
    "                img = str(img).replace(',', '')[1: -1].strip()\n",
    "\n",
    "                fdf.loc[i] = [view_map[k], img, height, width, p]\n",
    "            except Exception as e:\n",
    "                print(f\"Error occurred while processing '{pic_path}': {e}\")\n",
    "\n",
    "        frames.append(fdf)\n",
    "        print(len(frames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "wBzxZUtpRENo"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>view</th>\n",
       "      <th>pixels</th>\n",
       "      <th>height</th>\n",
       "      <th>width</th>\n",
       "      <th>usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>247 247 248 248 249 249 249 249 248 249 250 25...</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>seg_train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>113 114 113 111 111 113 114 112 113 112 111 11...</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>seg_train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>181 181 181 181 181 181 181 181 182 182 185 17...</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>seg_train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>196 168 171 167 169 171 167 161 162 170 171 17...</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>seg_train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>26 26 27 27 27 27 27 27 27 27 26 26 26 27 28 2...</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>seg_train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17029</th>\n",
       "      <td>5</td>\n",
       "      <td>110 115 80 127 213 165 172 179 47 102 81 196 2...</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>seg_test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17030</th>\n",
       "      <td>5</td>\n",
       "      <td>50 58 66 74 83 91 91 87 98 104 93 147 255 251 ...</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>seg_test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17031</th>\n",
       "      <td>5</td>\n",
       "      <td>69 69 69 69 69 69 70 70 70 70 70 70 70 71 71 7...</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>seg_test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17032</th>\n",
       "      <td>5</td>\n",
       "      <td>150 152 153 151 151 153 154 152 154 154 154 15...</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>seg_test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17033</th>\n",
       "      <td>5</td>\n",
       "      <td>1 25 18 19 19 19 19 19 19 21 22 20 18 18 20 20...</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>seg_test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17034 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       view                                             pixels  height  width  \\\n",
       "0         0  247 247 248 248 249 249 249 249 248 249 250 25...     150    150   \n",
       "1         0  113 114 113 111 111 113 114 112 113 112 111 11...     150    150   \n",
       "2         0  181 181 181 181 181 181 181 181 182 182 185 17...     150    150   \n",
       "3         0  196 168 171 167 169 171 167 161 162 170 171 17...     150    150   \n",
       "4         0  26 26 27 27 27 27 27 27 27 27 26 26 26 27 28 2...     150    150   \n",
       "...     ...                                                ...     ...    ...   \n",
       "17029     5  110 115 80 127 213 165 172 179 47 102 81 196 2...     150    150   \n",
       "17030     5  50 58 66 74 83 91 91 87 98 104 93 147 255 251 ...     150    150   \n",
       "17031     5  69 69 69 69 69 69 70 70 70 70 70 70 70 71 71 7...     150    150   \n",
       "17032     5  150 152 153 151 151 153 154 152 154 154 154 15...     150    150   \n",
       "17033     5  1 25 18 19 19 19 19 19 19 21 22 20 18 18 20 20...     150    150   \n",
       "\n",
       "           usage  \n",
       "0      seg_train  \n",
       "1      seg_train  \n",
       "2      seg_train  \n",
       "3      seg_train  \n",
       "4      seg_train  \n",
       "...          ...  \n",
       "17029   seg_test  \n",
       "17030   seg_test  \n",
       "17031   seg_test  \n",
       "17032   seg_test  \n",
       "17033   seg_test  \n",
       "\n",
       "[17034 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_df = pd.read_csv(r'C:\\Users\\SHALAKA\\Downloads\\imageclassification.csv')\n",
    "image_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "lCBysVYgRviC"
   },
   "outputs": [],
   "source": [
    "def pixel_convert(df, chunk_size=100):\n",
    "\n",
    "    new_df = df.copy()\n",
    "\n",
    "    num_chunks = len(new_df) // chunk_size + 1\n",
    "    for i in range(num_chunks):\n",
    "        start_idx = i * chunk_size\n",
    "        end_idx = min((i + 1) * chunk_size, len(new_df))\n",
    "        df_chunk = new_df.iloc[start_idx:end_idx].copy()\n",
    "\n",
    "\n",
    "        df_chunk['pixels'] = df_chunk['pixels'].apply(lambda x: x.split())\n",
    "        df_chunk['pixels'] = df_chunk['pixels'].apply(lambda x: [int(pixel) for pixel in x])\n",
    "        df_chunk['pixels'] = df_chunk.apply(lambda row: np.array(row['pixels']).reshape(row['height'], row['width']), axis=1)\n",
    "\n",
    "        new_df.iloc[start_idx:end_idx] = df_chunk\n",
    "\n",
    "    return new_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "XnSwOXvPR2yK"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>view</th>\n",
       "      <th>pixels</th>\n",
       "      <th>height</th>\n",
       "      <th>width</th>\n",
       "      <th>usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[[247, 247, 248, 248, 249, 249, 249, 249, 248,...</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>seg_train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[[113, 114, 113, 111, 111, 113, 114, 112, 113,...</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>seg_train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[[181, 181, 181, 181, 181, 181, 181, 181, 182,...</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>seg_train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[[196, 168, 171, 167, 169, 171, 167, 161, 162,...</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>seg_train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[[26, 26, 27, 27, 27, 27, 27, 27, 27, 27, 26, ...</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>seg_train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17029</th>\n",
       "      <td>5</td>\n",
       "      <td>[[110, 115, 80, 127, 213, 165, 172, 179, 47, 1...</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>seg_test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17030</th>\n",
       "      <td>5</td>\n",
       "      <td>[[50, 58, 66, 74, 83, 91, 91, 87, 98, 104, 93,...</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>seg_test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17031</th>\n",
       "      <td>5</td>\n",
       "      <td>[[69, 69, 69, 69, 69, 69, 70, 70, 70, 70, 70, ...</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>seg_test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17032</th>\n",
       "      <td>5</td>\n",
       "      <td>[[150, 152, 153, 151, 151, 153, 154, 152, 154,...</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>seg_test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17033</th>\n",
       "      <td>5</td>\n",
       "      <td>[[1, 25, 18, 19, 19, 19, 19, 19, 19, 21, 22, 2...</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>seg_test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17034 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       view                                             pixels  height  width  \\\n",
       "0         0  [[247, 247, 248, 248, 249, 249, 249, 249, 248,...     150    150   \n",
       "1         0  [[113, 114, 113, 111, 111, 113, 114, 112, 113,...     150    150   \n",
       "2         0  [[181, 181, 181, 181, 181, 181, 181, 181, 182,...     150    150   \n",
       "3         0  [[196, 168, 171, 167, 169, 171, 167, 161, 162,...     150    150   \n",
       "4         0  [[26, 26, 27, 27, 27, 27, 27, 27, 27, 27, 26, ...     150    150   \n",
       "...     ...                                                ...     ...    ...   \n",
       "17029     5  [[110, 115, 80, 127, 213, 165, 172, 179, 47, 1...     150    150   \n",
       "17030     5  [[50, 58, 66, 74, 83, 91, 91, 87, 98, 104, 93,...     150    150   \n",
       "17031     5  [[69, 69, 69, 69, 69, 69, 70, 70, 70, 70, 70, ...     150    150   \n",
       "17032     5  [[150, 152, 153, 151, 151, 153, 154, 152, 154,...     150    150   \n",
       "17033     5  [[1, 25, 18, 19, 19, 19, 19, 19, 19, 21, 22, 2...     150    150   \n",
       "\n",
       "           usage  \n",
       "0      seg_train  \n",
       "1      seg_train  \n",
       "2      seg_train  \n",
       "3      seg_train  \n",
       "4      seg_train  \n",
       "...          ...  \n",
       "17029   seg_test  \n",
       "17030   seg_test  \n",
       "17031   seg_test  \n",
       "17032   seg_test  \n",
       "17033   seg_test  \n",
       "\n",
       "[17034 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converted_df = pixel_convert(image_df)\n",
    "converted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "wRn0GDNmR65f"
   },
   "outputs": [],
   "source": [
    "def apply_zero_padding(pixel_array, original_height, original_width, target_height, target_width):\n",
    "\n",
    "    img = np.array(pixel_array).reshape(original_height, original_width)\n",
    "\n",
    "\n",
    "    pad_height = max(0, target_height - original_height)\n",
    "    pad_width = max(0, target_width - original_width)\n",
    "\n",
    "\n",
    "    top_pad = pad_height // 2\n",
    "    bottom_pad = pad_height - top_pad\n",
    "    left_pad = pad_width // 2\n",
    "    right_pad = pad_width - left_pad\n",
    "\n",
    "\n",
    "    padded_img = cv2.copyMakeBorder(img, top_pad, bottom_pad, left_pad, right_pad, cv2.BORDER_CONSTANT, value=0)\n",
    "\n",
    "    return padded_img\n",
    "\n",
    "max_height = converted_df['height'].max()\n",
    "max_width = converted_df['width'].max()\n",
    "\n",
    "\n",
    "converted_df['pixels'] = converted_df.apply(lambda row: apply_zero_padding(row['pixels'], row['height'], row['width'], max_height, max_width), axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KNpLLHdeaecE"
   },
   "source": [
    "**Train Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kaVYxSR-aipt",
    "outputId": "4ce7d3ed-8873-4e62-e8a0-148bb68142de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Shape: (11227, 5)\n",
      "Validation Data Shape: (2807, 5)\n",
      "Test Data Shape: (3000, 5)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming your DataFrame is named converted_df\n",
    "# Splitting the DataFrame into train, test, and validation sets based on the 'usage' column\n",
    "train_df = converted_df[converted_df['usage'] == 'seg_train']\n",
    "test_df = converted_df[converted_df['usage'] == 'seg_test']\n",
    "\n",
    "# Further splitting the train data into train and validation sets\n",
    "train_data, val_data = train_test_split(train_df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print shapes of the datasets (optional)\n",
    "print(f\"Train Data Shape: {train_data.shape}\")\n",
    "print(f\"Validation Data Shape: {val_data.shape}\")\n",
    "print(f\"Test Data Shape: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "yheaPhipardv"
   },
   "outputs": [],
   "source": [
    "def preprocess_images(data):\n",
    "    # Convert the 'pixels' column to numpy array and normalize pixel values\n",
    "    images = np.array(data['pixels'].tolist()) / 255.0\n",
    "\n",
    "    # Reshape the images to the required shape for CNN (assuming grayscale images)\n",
    "    images = images.reshape(-1, 150, 150, 1)  # Adjust dimensions as needed\n",
    "    return images\n",
    "\n",
    "# Preprocess the images for training, validation, and test sets\n",
    "train_images = preprocess_images(train_data)\n",
    "val_images = preprocess_images(val_data)\n",
    "test_images = preprocess_images(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "NdMM_G_8bet0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "351/351 [==============================] - 80s 220ms/step - loss: 1.5773 - accuracy: 0.3854 - val_loss: 2.1643 - val_accuracy: 0.2027\n",
      "Epoch 2/80\n",
      "351/351 [==============================] - 74s 211ms/step - loss: 1.2294 - accuracy: 0.5122 - val_loss: 1.0855 - val_accuracy: 0.5789\n",
      "Epoch 3/80\n",
      "351/351 [==============================] - 75s 214ms/step - loss: 1.1195 - accuracy: 0.5640 - val_loss: 0.9708 - val_accuracy: 0.6213\n",
      "Epoch 4/80\n",
      "351/351 [==============================] - 75s 214ms/step - loss: 1.0453 - accuracy: 0.5992 - val_loss: 0.9179 - val_accuracy: 0.6437\n",
      "Epoch 5/80\n",
      "351/351 [==============================] - 76s 216ms/step - loss: 0.9865 - accuracy: 0.6239 - val_loss: 0.8765 - val_accuracy: 0.6580\n",
      "Epoch 6/80\n",
      "351/351 [==============================] - 76s 218ms/step - loss: 0.9394 - accuracy: 0.6418 - val_loss: 0.8436 - val_accuracy: 0.6772\n",
      "Epoch 7/80\n",
      "351/351 [==============================] - 78s 223ms/step - loss: 0.8864 - accuracy: 0.6679 - val_loss: 0.8061 - val_accuracy: 0.6965\n",
      "Epoch 8/80\n",
      "351/351 [==============================] - 78s 222ms/step - loss: 0.8526 - accuracy: 0.6739 - val_loss: 0.7797 - val_accuracy: 0.7082\n",
      "Epoch 9/80\n",
      "351/351 [==============================] - 77s 220ms/step - loss: 0.8195 - accuracy: 0.6937 - val_loss: 0.7641 - val_accuracy: 0.7150\n",
      "Epoch 10/80\n",
      "351/351 [==============================] - 79s 224ms/step - loss: 0.7911 - accuracy: 0.7073 - val_loss: 0.7415 - val_accuracy: 0.7296\n",
      "Epoch 11/80\n",
      "351/351 [==============================] - 80s 229ms/step - loss: 0.7577 - accuracy: 0.7180 - val_loss: 0.7239 - val_accuracy: 0.7246\n",
      "Epoch 12/80\n",
      "351/351 [==============================] - 83s 235ms/step - loss: 0.7452 - accuracy: 0.7262 - val_loss: 0.7050 - val_accuracy: 0.7382\n",
      "Epoch 13/80\n",
      "351/351 [==============================] - 81s 230ms/step - loss: 0.7173 - accuracy: 0.7327 - val_loss: 0.6956 - val_accuracy: 0.7399\n",
      "Epoch 14/80\n",
      "351/351 [==============================] - 81s 229ms/step - loss: 0.6950 - accuracy: 0.7451 - val_loss: 0.6814 - val_accuracy: 0.7421\n",
      "Epoch 15/80\n",
      "351/351 [==============================] - 81s 231ms/step - loss: 0.6825 - accuracy: 0.7527 - val_loss: 0.6777 - val_accuracy: 0.7439\n",
      "Epoch 16/80\n",
      "351/351 [==============================] - 82s 234ms/step - loss: 0.6706 - accuracy: 0.7511 - val_loss: 0.6639 - val_accuracy: 0.7517\n",
      "Epoch 17/80\n",
      "351/351 [==============================] - 84s 238ms/step - loss: 0.6469 - accuracy: 0.7674 - val_loss: 0.6601 - val_accuracy: 0.7538\n",
      "Epoch 18/80\n",
      "351/351 [==============================] - 83s 235ms/step - loss: 0.6382 - accuracy: 0.7682 - val_loss: 0.6533 - val_accuracy: 0.7570\n",
      "Epoch 19/80\n",
      "351/351 [==============================] - 82s 234ms/step - loss: 0.6292 - accuracy: 0.7726 - val_loss: 0.6426 - val_accuracy: 0.7610\n",
      "Epoch 20/80\n",
      "351/351 [==============================] - 82s 234ms/step - loss: 0.6139 - accuracy: 0.7826 - val_loss: 0.6380 - val_accuracy: 0.7667\n",
      "Epoch 21/80\n",
      "351/351 [==============================] - 83s 236ms/step - loss: 0.6169 - accuracy: 0.7786 - val_loss: 0.6336 - val_accuracy: 0.7667\n",
      "Epoch 22/80\n",
      "351/351 [==============================] - 85s 242ms/step - loss: 0.5895 - accuracy: 0.7869 - val_loss: 0.6323 - val_accuracy: 0.7670\n",
      "Epoch 23/80\n",
      "351/351 [==============================] - 86s 246ms/step - loss: 0.5949 - accuracy: 0.7879 - val_loss: 0.6278 - val_accuracy: 0.7720\n",
      "Epoch 24/80\n",
      "351/351 [==============================] - 83s 236ms/step - loss: 0.5750 - accuracy: 0.7943 - val_loss: 0.6212 - val_accuracy: 0.7752\n",
      "Epoch 25/80\n",
      "351/351 [==============================] - 83s 236ms/step - loss: 0.5738 - accuracy: 0.7968 - val_loss: 0.6228 - val_accuracy: 0.7734\n",
      "Epoch 26/80\n",
      "351/351 [==============================] - 83s 236ms/step - loss: 0.5625 - accuracy: 0.7970 - val_loss: 0.6234 - val_accuracy: 0.7699\n",
      "Epoch 27/80\n",
      "351/351 [==============================] - 83s 235ms/step - loss: 0.5601 - accuracy: 0.7991 - val_loss: 0.6175 - val_accuracy: 0.7727\n",
      "Epoch 28/80\n",
      "351/351 [==============================] - 87s 249ms/step - loss: 0.5470 - accuracy: 0.8027 - val_loss: 0.6135 - val_accuracy: 0.7731\n",
      "Epoch 29/80\n",
      "351/351 [==============================] - 89s 253ms/step - loss: 0.5506 - accuracy: 0.8064 - val_loss: 0.6156 - val_accuracy: 0.7738\n",
      "Epoch 30/80\n",
      "351/351 [==============================] - 88s 252ms/step - loss: 0.5372 - accuracy: 0.8041 - val_loss: 0.6068 - val_accuracy: 0.7766\n",
      "Epoch 31/80\n",
      "351/351 [==============================] - 85s 241ms/step - loss: 0.5282 - accuracy: 0.8106 - val_loss: 0.6062 - val_accuracy: 0.7756\n",
      "Epoch 32/80\n",
      "351/351 [==============================] - 83s 237ms/step - loss: 0.5325 - accuracy: 0.8105 - val_loss: 0.6026 - val_accuracy: 0.7784\n",
      "Epoch 33/80\n",
      "351/351 [==============================] - 83s 237ms/step - loss: 0.5268 - accuracy: 0.8124 - val_loss: 0.6050 - val_accuracy: 0.7756\n",
      "Epoch 34/80\n",
      "351/351 [==============================] - 84s 239ms/step - loss: 0.5166 - accuracy: 0.8138 - val_loss: 0.6019 - val_accuracy: 0.7802\n",
      "Epoch 35/80\n",
      "351/351 [==============================] - 83s 236ms/step - loss: 0.5130 - accuracy: 0.8180 - val_loss: 0.5999 - val_accuracy: 0.7809\n",
      "Epoch 36/80\n",
      "351/351 [==============================] - 84s 239ms/step - loss: 0.5083 - accuracy: 0.8194 - val_loss: 0.6023 - val_accuracy: 0.7745\n",
      "Epoch 37/80\n",
      "351/351 [==============================] - 83s 238ms/step - loss: 0.5007 - accuracy: 0.8198 - val_loss: 0.5964 - val_accuracy: 0.7805\n",
      "Epoch 38/80\n",
      "351/351 [==============================] - 82s 235ms/step - loss: 0.4999 - accuracy: 0.8204 - val_loss: 0.5979 - val_accuracy: 0.7798\n",
      "Epoch 39/80\n",
      "351/351 [==============================] - 82s 235ms/step - loss: 0.4976 - accuracy: 0.8236 - val_loss: 0.5929 - val_accuracy: 0.7805\n",
      "Epoch 40/80\n",
      "351/351 [==============================] - 82s 235ms/step - loss: 0.4889 - accuracy: 0.8293 - val_loss: 0.5944 - val_accuracy: 0.7791\n",
      "Epoch 41/80\n",
      "351/351 [==============================] - 84s 238ms/step - loss: 0.4857 - accuracy: 0.8280 - val_loss: 0.5912 - val_accuracy: 0.7830\n",
      "Epoch 42/80\n",
      "351/351 [==============================] - 83s 236ms/step - loss: 0.4870 - accuracy: 0.8299 - val_loss: 0.5928 - val_accuracy: 0.7813\n",
      "Epoch 43/80\n",
      "351/351 [==============================] - 84s 239ms/step - loss: 0.4805 - accuracy: 0.8284 - val_loss: 0.5912 - val_accuracy: 0.7820\n",
      "Epoch 44/80\n",
      "351/351 [==============================] - 83s 235ms/step - loss: 0.4842 - accuracy: 0.8301 - val_loss: 0.5898 - val_accuracy: 0.7845\n",
      "Epoch 45/80\n",
      "351/351 [==============================] - 83s 235ms/step - loss: 0.4834 - accuracy: 0.8277 - val_loss: 0.5898 - val_accuracy: 0.7823\n",
      "Epoch 46/80\n",
      "351/351 [==============================] - 83s 237ms/step - loss: 0.4763 - accuracy: 0.8350 - val_loss: 0.5892 - val_accuracy: 0.7848\n",
      "Epoch 47/80\n",
      "351/351 [==============================] - 83s 237ms/step - loss: 0.4797 - accuracy: 0.8266 - val_loss: 0.5868 - val_accuracy: 0.7834\n",
      "Epoch 48/80\n",
      "351/351 [==============================] - 83s 236ms/step - loss: 0.4604 - accuracy: 0.8370 - val_loss: 0.5891 - val_accuracy: 0.7855\n",
      "Epoch 49/80\n",
      "351/351 [==============================] - 84s 240ms/step - loss: 0.4662 - accuracy: 0.8361 - val_loss: 0.5865 - val_accuracy: 0.7845\n",
      "Epoch 50/80\n",
      "351/351 [==============================] - 84s 239ms/step - loss: 0.4683 - accuracy: 0.8358 - val_loss: 0.5869 - val_accuracy: 0.7841\n",
      "Epoch 51/80\n",
      "351/351 [==============================] - 83s 237ms/step - loss: 0.4616 - accuracy: 0.8390 - val_loss: 0.5866 - val_accuracy: 0.7866\n",
      "Epoch 52/80\n",
      "351/351 [==============================] - 83s 237ms/step - loss: 0.4559 - accuracy: 0.8416 - val_loss: 0.5866 - val_accuracy: 0.7845\n",
      "Epoch 53/80\n",
      "351/351 [==============================] - 83s 236ms/step - loss: 0.4548 - accuracy: 0.8394 - val_loss: 0.5851 - val_accuracy: 0.7841\n",
      "Epoch 54/80\n",
      "351/351 [==============================] - 83s 237ms/step - loss: 0.4516 - accuracy: 0.8434 - val_loss: 0.5846 - val_accuracy: 0.7841\n",
      "Epoch 55/80\n",
      "351/351 [==============================] - 83s 236ms/step - loss: 0.4565 - accuracy: 0.8390 - val_loss: 0.5825 - val_accuracy: 0.7862\n",
      "Epoch 56/80\n",
      "351/351 [==============================] - 83s 236ms/step - loss: 0.4537 - accuracy: 0.8423 - val_loss: 0.5820 - val_accuracy: 0.7838\n",
      "Epoch 57/80\n",
      "351/351 [==============================] - 82s 233ms/step - loss: 0.4533 - accuracy: 0.8410 - val_loss: 0.5817 - val_accuracy: 0.7859\n",
      "Epoch 58/80\n",
      "351/351 [==============================] - 83s 235ms/step - loss: 0.4447 - accuracy: 0.8443 - val_loss: 0.5820 - val_accuracy: 0.7887\n",
      "Epoch 59/80\n",
      "351/351 [==============================] - 82s 233ms/step - loss: 0.4511 - accuracy: 0.8406 - val_loss: 0.5818 - val_accuracy: 0.7859\n",
      "Epoch 60/80\n",
      "351/351 [==============================] - 82s 233ms/step - loss: 0.4495 - accuracy: 0.8419 - val_loss: 0.5808 - val_accuracy: 0.7873\n",
      "Epoch 61/80\n",
      "351/351 [==============================] - 82s 233ms/step - loss: 0.4393 - accuracy: 0.8477 - val_loss: 0.5812 - val_accuracy: 0.7873\n",
      "Epoch 62/80\n",
      "351/351 [==============================] - 82s 234ms/step - loss: 0.4431 - accuracy: 0.8462 - val_loss: 0.5818 - val_accuracy: 0.7838\n",
      "Epoch 63/80\n",
      "351/351 [==============================] - 82s 233ms/step - loss: 0.4427 - accuracy: 0.8447 - val_loss: 0.5816 - val_accuracy: 0.7848\n",
      "Epoch 64/80\n",
      "351/351 [==============================] - 82s 233ms/step - loss: 0.4434 - accuracy: 0.8431 - val_loss: 0.5803 - val_accuracy: 0.7862\n",
      "Epoch 65/80\n",
      "351/351 [==============================] - 83s 235ms/step - loss: 0.4351 - accuracy: 0.8484 - val_loss: 0.5798 - val_accuracy: 0.7866\n",
      "Epoch 66/80\n",
      "351/351 [==============================] - 84s 238ms/step - loss: 0.4337 - accuracy: 0.8501 - val_loss: 0.5793 - val_accuracy: 0.7848\n",
      "Epoch 67/80\n",
      "351/351 [==============================] - 83s 236ms/step - loss: 0.4384 - accuracy: 0.8488 - val_loss: 0.5805 - val_accuracy: 0.7859\n",
      "Epoch 68/80\n",
      "351/351 [==============================] - 82s 235ms/step - loss: 0.4446 - accuracy: 0.8487 - val_loss: 0.5795 - val_accuracy: 0.7866\n",
      "Epoch 69/80\n",
      "351/351 [==============================] - 82s 233ms/step - loss: 0.4439 - accuracy: 0.8419 - val_loss: 0.5785 - val_accuracy: 0.7859\n",
      "Epoch 70/80\n",
      "351/351 [==============================] - 82s 234ms/step - loss: 0.4379 - accuracy: 0.8485 - val_loss: 0.5778 - val_accuracy: 0.7852\n",
      "Epoch 71/80\n",
      "351/351 [==============================] - 82s 234ms/step - loss: 0.4364 - accuracy: 0.8505 - val_loss: 0.5787 - val_accuracy: 0.7859\n",
      "Epoch 72/80\n",
      "351/351 [==============================] - 83s 238ms/step - loss: 0.4261 - accuracy: 0.8499 - val_loss: 0.5785 - val_accuracy: 0.7855\n",
      "Epoch 73/80\n",
      "351/351 [==============================] - 83s 236ms/step - loss: 0.4296 - accuracy: 0.8529 - val_loss: 0.5783 - val_accuracy: 0.7895\n",
      "Epoch 74/80\n",
      "351/351 [==============================] - 83s 236ms/step - loss: 0.4365 - accuracy: 0.8491 - val_loss: 0.5778 - val_accuracy: 0.7880\n",
      "Epoch 75/80\n",
      "351/351 [==============================] - 84s 239ms/step - loss: 0.4285 - accuracy: 0.8487 - val_loss: 0.5777 - val_accuracy: 0.7884\n",
      "Epoch 76/80\n",
      "351/351 [==============================] - 82s 234ms/step - loss: 0.4403 - accuracy: 0.8449 - val_loss: 0.5769 - val_accuracy: 0.7877\n",
      "Epoch 77/80\n",
      "351/351 [==============================] - 82s 233ms/step - loss: 0.4288 - accuracy: 0.8523 - val_loss: 0.5769 - val_accuracy: 0.7887\n",
      "Epoch 78/80\n",
      "351/351 [==============================] - 83s 235ms/step - loss: 0.4337 - accuracy: 0.8492 - val_loss: 0.5767 - val_accuracy: 0.7898\n",
      "Epoch 79/80\n",
      "351/351 [==============================] - 83s 238ms/step - loss: 0.4276 - accuracy: 0.8552 - val_loss: 0.5764 - val_accuracy: 0.7898\n",
      "Epoch 80/80\n",
      "351/351 [==============================] - 82s 233ms/step - loss: 0.4259 - accuracy: 0.8534 - val_loss: 0.5766 - val_accuracy: 0.7884\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Add Convolutional layers\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(150, 150, 1), strides=(1, 1), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3),  strides=(1, 1), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3),  strides=(2, 2), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flatten the output of the convolutional layers\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add Dense layers\n",
    "#model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "#learning_rate = 0.00001\n",
    "\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=1e-5,\n",
    "    decay_steps=2000,  \n",
    "    decay_rate=0.8  )\n",
    "\n",
    "optimizer = Adam(learning_rate=lr_schedule)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "# Train the model using your training data and validate it using validation data\n",
    "history = model.fit(train_images, train_data['view'], \n",
    "                    epochs=80, \n",
    "                    validation_data=(val_images, val_data['view']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "Yy6TfySdc8js"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 6s 58ms/step - loss: 0.5947 - accuracy: 0.7833\n",
      "Test accuracy: 0.7833333611488342\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test set\n",
    "test_loss, test_acc = model.evaluate(test_images, test_df['view'])\n",
    "print(f'Test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\SHALAKA\\Desktop\\MachineL\\my_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\SHALAKA\\Desktop\\MachineL\\my_model\\assets\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Save the entire model\n",
    "model.save(r'C:\\Users\\SHALAKA\\Desktop\\MachineL\\my_model')\n",
    "\n",
    "# Load the model\n",
    "loaded_model = tf.keras.models.load_model('my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
